import os
import whisper
from moviepy.editor import VideoFileClip
import subprocess

# è¨­å®š
input_video_path = "input.mp4"
extracted_audio_path = "audio.wav"
output_srt_path = "subtitles.srt"
output_video_path = "output_with_subs.mp4"

# å‰Šé™¤å‡¦ç†
for path in [extracted_audio_path, output_srt_path, output_video_path]:
    if os.path.exists(path):
        os.remove(path)
        print(f"ğŸ§¹ å‰Šé™¤ã—ã¾ã—ãŸ: {path}")

# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ï¼ˆWhisperã®æ™‚é–“ â†’ SRTå½¢å¼ï¼‰
def format_timestamp(seconds: float) -> str:
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

# ã‚¹ãƒ†ãƒƒãƒ—1ï¼šmp4 â†’ wav
print("ğŸï¸ MP4 â†’ WAV ã«å¤‰æ›ä¸­...")
video = VideoFileClip(input_video_path)
video.audio.write_audiofile(extracted_audio_path)

# ã‚¹ãƒ†ãƒƒãƒ—2ï¼šWAV ã‚’ Whisper ã§æ–‡å­—èµ·ã“ã—
print("ğŸ—£ Whisper ã«ã‚ˆã‚‹è‹±èªæ–‡å­—èµ·ã“ã—ä¸­...")
model = whisper.load_model("base")
result = model.transcribe(extracted_audio_path, task="transcribe")

# ã‚¹ãƒ†ãƒƒãƒ—3ï¼šSRTãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
print("ğŸ’¬ SRTå­—å¹•ã‚’ä¿å­˜ä¸­...")
with open(output_srt_path, "w", encoding="utf-8") as f:
    for i, segment in enumerate(result["segments"]):
        start = segment["start"]
        end = segment["end"]
        text = segment["text"]
        f.write(f"{i+1}\n")
        f.write(f"{format_timestamp(start)} --> {format_timestamp(end)}\n")
        f.write(f"{text}\n\n")

# ã‚¹ãƒ†ãƒƒãƒ—4ï¼šffmpegã§å­—å¹•ã‚’å‹•ç”»ã«ç„¼ãä»˜ã‘
print("ğŸ“½ å­—å¹•ã‚’å‹•ç”»ã«ç„¼ãè¾¼ã¿ä¸­...")
subprocess.run([
    "ffmpeg",
    "-i", input_video_path,
    "-vf", f"subtitles={output_srt_path}:force_style='FontName=NotoSansCJKjp'",
    "-c:a", "copy",
    output_video_path
])

print("âœ… å®Œäº†ï¼å­—å¹•ä»˜ãå‹•ç”»ï¼š", output_video_path)
