import whisper
from googletrans import Translator
from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters

# Whisperãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
print("ğŸ—£ Whisperã§æ–‡å­—èµ·ã“ã—ä¸­...")
model = whisper.load_model("base")
result = model.transcribe("audio.wav", task="transcribe")

# å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’1ã¤ã®æ–‡å­—åˆ—ã«çµåˆ
full_text = " ".join([seg["text"].strip() for seg in result["segments"]])

# æ–‡å˜ä½ã«åˆ†å‰²ï¼ˆPunktã‚’ç›´æ¥ä½¿ç”¨ï¼‰
punkt_params = PunktParameters()
tokenizer = PunktSentenceTokenizer(punkt_params)
english_sentences = tokenizer.tokenize(full_text)

# ç¿»è¨³å‡¦ç†
print("ğŸŒ Googleç¿»è¨³ã§æ–‡ã”ã¨ã«ç¿»è¨³ä¸­...")
translator = Translator()
output_lines = []

for i, en_text in enumerate(english_sentences, start=1):
    ja_text = translator.translate(en_text, src="en", dest="ja").text
    output_lines.append(f"[{i}]")
    output_lines.append(f"EN: {en_text}")
    output_lines.append(f"JA: {ja_text}")
    output_lines.append("")  # ç©ºè¡Œã§åŒºåˆ‡ã‚‹

# çµæœã‚’ä¿å­˜
with open("translated_output.txt", "w", encoding="utf-8") as f:
    f.write("\n".join(output_lines))

print("âœ… å®Œäº†ï¼ç¿»è¨³çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ translated_output.txt")
